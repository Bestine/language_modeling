{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94dc143f",
   "metadata": {},
   "source": [
    "**Load the required packages and data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "194f6fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 11:02:30.306648: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-13 11:02:30.306734: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-13 11:02:32.011232: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-13 11:02:54.338883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-13 11:02:54.339146: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-13 11:02:54.339161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-04-13 11:03:24.764158: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-13 11:03:24.775769: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-13 11:03:24.775946: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (streetanalyst): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "# Load the required packages \n",
    "import numpy as np\n",
    "import csv\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ec883f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence    structure   direct_object   indirect_object']\n",
      "['The driver gave the bracelet to the grandpa', 'DO', 'bracelet', 'grandpa']\n",
      "['The driver gave the grandpa the bracelet', 'PO', 'bracelet', 'grandpa']\n",
      "['The veteran gave the flag to the uncle', 'DO', 'flag', 'uncle']\n",
      "['The veteran gave the uncle the flag', 'PO', 'flag', 'uncle']\n",
      "['The guy gave the cotton to the soldier', 'DO', 'cotton', 'soldier']\n",
      "['The guy gave the soldier the cotton', 'PO', 'cotton', 'soldier']\n",
      "['The astronaut gave the mustard to the boy', 'DO', 'mustard', 'boy']\n",
      "['The astronaut gave the boy the mustard', 'PO', 'mustard', 'boy']\n",
      "['The referee gave the clarinet to the commander', 'DO', 'clarinet', 'commander']\n",
      "['The referee gave the commander the clarinet', 'PO', 'clarinet', 'commander']\n",
      "['The teenager gave the pliers to the human', 'DO', 'pliers', 'human']\n",
      "['The teenager gave the human the pliers', 'PO', 'pliers', 'human']\n",
      "['The boy gave the loaf to the man', 'DO', 'loaf', 'man']\n",
      "['The boy gave the man the loaf', 'PO', 'loaf', 'man']\n",
      "['The professor gave the mustard to the man', 'DO', 'mustard', 'man']\n",
      "['The professor gave the man the mustard', 'PO', 'mustard', 'man']\n",
      "['The surgeon gave the decoration to the grandpa', 'DO', 'decoration', 'grandpa']\n",
      "['The surgeon gave the grandpa the decoration', 'PO', 'decoration', 'grandpa']\n",
      "['The sheriff gave the map to the referee', 'DO', 'map', 'referee']\n",
      "['The sheriff gave the referee the map', 'PO', 'map', 'referee']\n",
      "['The uncle gave the loaf to the citizen', 'DO', 'loaf', 'citizen']\n",
      "['The uncle gave the citizen the loaf', 'PO', 'loaf', 'citizen']\n",
      "['The student gave the seat to the girlfriend', 'DO', 'seat', 'girlfriend']\n",
      "['The student gave the girlfriend the seat', 'PO', 'seat', 'girlfriend']\n",
      "['The contractor gave the poison to the detective', 'DO', 'poison', 'detective']\n",
      "['The contractor gave the detective the poison', 'PO', 'poison', 'detective']\n",
      "['The salesman gave the loaf to the grandpa', 'DO', 'loaf', 'grandpa']\n",
      "['The salesman gave the grandpa the loaf', 'PO', 'loaf', 'grandpa']\n",
      "['The banker gave the rock to the soldier', 'DO', 'rock', 'soldier']\n",
      "['The banker gave the soldier the rock', 'PO', 'rock', 'soldier']\n",
      "['The engineer gave the sky to the sheriff', 'DO', 'sky', 'sheriff']\n",
      "['The engineer gave the sheriff the sky', 'PO', 'sky', 'sheriff']\n",
      "['The girlfriend gave the sky to the person', 'DO', 'sky', 'person']\n",
      "['The girlfriend gave the person the sky', 'PO', 'sky', 'person']\n",
      "['The mother gave the map to the teenager', 'DO', 'map', 'teenager']\n",
      "['The mother gave the teenager the map', 'PO', 'map', 'teenager']\n",
      "['The preacher gave the flag to the swimmer', 'DO', 'flag', 'swimmer']\n",
      "['The preacher gave the swimmer the flag', 'PO', 'flag', 'swimmer']\n",
      "['The human gave the triangle to the bride', 'DO', 'triangle', 'bride']\n",
      "['The human gave the bride the triangle', 'PO', 'triangle', 'bride']\n",
      "['The commander gave the box to the sheriff', 'DO', 'box', 'sheriff']\n",
      "['The commander gave the sheriff the box', 'PO', 'box', 'sheriff']\n",
      "['The fireman gave the triangle to the astronaut', 'DO', 'triangle', 'astronaut']\n",
      "['The fireman gave the astronaut the triangle', 'PO', 'triangle', 'astronaut']\n",
      "['The sailor gave the pliers to the student', 'DO', 'pliers', 'student']\n",
      "['The sailor gave the student the pliers', 'PO', 'pliers', 'student']\n",
      "['The chief gave the fog to the fireman', 'DO', 'fog', 'fireman']\n",
      "['The chief gave the fireman the fog', 'PO', 'fog', 'fireman']\n",
      "['The girl gave the jug to the surgeon', 'DO', 'jug', 'surgeon']\n",
      "['The girl gave the surgeon the jug', 'PO', 'jug', 'surgeon']\n",
      "['The person gave the clarinet to the man', 'DO', 'clarinet', 'man']\n",
      "['The person gave the man the clarinet', 'PO', 'clarinet', 'man']\n",
      "['The boyfriend gave the bracelet to the banker', 'DO', 'bracelet', 'banker']\n",
      "['The boyfriend gave the banker the bracelet', 'PO', 'bracelet', 'banker']\n",
      "['The technician gave the toast to the principal', 'DO', 'toast', 'principal']\n",
      "['The technician gave the principal the toast', 'PO', 'toast', 'principal']\n",
      "['The grandpa gave the whiskey to the girlfriend', 'DO', 'whiskey', 'girlfriend']\n",
      "['The grandpa gave the girlfriend the whiskey', 'PO', 'whiskey', 'girlfriend']\n",
      "['The sergeant gave the gravel to the commander', 'DO', 'gravel', 'commander']\n",
      "['The sergeant gave the commander the gravel', 'PO', 'gravel', 'commander']\n",
      "['The bride gave the lever to the fireman', 'DO', 'lever', 'fireman']\n",
      "['The bride gave the fireman the lever', 'PO', 'lever', 'fireman']\n",
      "['The soldier gave the sky to the detective', 'DO', 'sky', 'detective']\n",
      "['The soldier gave the detective the sky', 'PO', 'sky', 'detective']\n",
      "['The gal gave the toast to the human', 'DO', 'toast', 'human']\n",
      "['The gal gave the human the toast', 'PO', 'toast', 'human']\n",
      "['The swimmer gave the loaf to the principal', 'DO', 'loaf', 'principal']\n",
      "['The swimmer gave the principal the loaf', 'PO', 'loaf', 'principal']\n",
      "['The principal gave the stone to the boy', 'DO', 'stone', 'boy']\n",
      "['The principal gave the boy the stone', 'PO', 'stone', 'boy']\n",
      "['The officer gave the region to the engineer', 'DO', 'region', 'engineer']\n",
      "['The officer gave the engineer the region', 'PO', 'region', 'engineer']\n",
      "['The citizen gave the region to the surgeon', 'DO', 'region', 'surgeon']\n",
      "['The citizen gave the surgeon the region', 'PO', 'region', 'surgeon']\n",
      "['The detective gave the razor to the surgeon', 'DO', 'razor', 'surgeon']\n",
      "['The detective gave the surgeon the razor', 'PO', 'razor', 'surgeon']\n",
      "['The man gave the spade to the technician', 'DO', 'spade', 'technician']\n",
      "['The man gave the technician the spade', 'PO', 'spade', 'technician']\n",
      "['The sister gave the poison to the engineer', 'DO', 'poison', 'engineer']\n",
      "['The sister gave the engineer the poison', 'PO', 'poison', 'engineer']\n"
     ]
    }
   ],
   "source": [
    "# Load the data \n",
    "with open(\"data/prototyping_sentences.tsv\") as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09393ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee4948b5",
   "metadata": {},
   "source": [
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890ff30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_structure(sentence):\n",
    "    sentence_structure = None\n",
    "    assert sentence_structure in {'DO', 'PO', None}\n",
    "    return sentence_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15afb5",
   "metadata": {},
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "def93329",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('language_modeling_env/lib/python3.7/site-packages/en_core_web_sm/en_core_web_sm-3.5.0')\n",
    "# nlp = spacy_stanza.load_pipeline(\"en\")\n",
    "\n",
    "def classify_sentence_structure(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'dobj':\n",
    "            dobj = token\n",
    "            print(dobj)\n",
    "        elif token.dep_ == 'dative':\n",
    "            iobj = token\n",
    "            print(iobj)\n",
    "        elif token.dep_ == 'pobj' and token.head.pos_ == 'ADP':\n",
    "            prep = token.head\n",
    "            pobj = token\n",
    "    if 'dobj' in locals() and 'dative' in locals():\n",
    "        return 'Double Object'\n",
    "    elif 'dobj' in locals() and 'pobj' in locals():\n",
    "        return 'Prepositional Object'\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b1b2cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lever\n",
      "to\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Prepositional Object'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTENCE = 'The bride gave the lever to the fireman'\n",
    "\n",
    "classify_sentence_structure(SENTENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe50ae7",
   "metadata": {},
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f1a51",
   "metadata": {},
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4f75ce",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9dbc4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_stc(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    #Find the dependency matchers\n",
    "    tokens_matchers = [matchers.dep_ for matchers in doc]\n",
    "    \n",
    "    if 'dative' in tokens_matchers and 'dobj' in tokens_matchers:\n",
    "        # Now check if it is a PO\n",
    "        if 'pobj'in tokens_matchers:\n",
    "            #confirm again \n",
    "            if tokens_matchers.index(\"dobj\") < tokens_matchers.index(\"dative\"):\n",
    "                sentence_structure = \"PO\"\n",
    "        else:\n",
    "            # Check for possible DO\n",
    "            tokens_matchers.index(\"dative\") < tokens_matchers.index(\"dobj\")\n",
    "            sentence_structure = \"DO\"\n",
    "            \n",
    "    else:\n",
    "        sentence_structure =  None\n",
    "        \n",
    "    return sentence_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59e99684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DO'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing \n",
    "SENTENCE = \"[laughter] my daughter handed me the phone and said here dad wake up\"\n",
    "\n",
    "\n",
    "clf_stc(SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2786810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy_stanza\n",
    "\n",
    "# nlp = spacy_stanza.load_pipeline(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc830ddb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E099] Invalid pattern: the first node of pattern should be an anchor node. The node should only contain RIGHT_ID and RIGHT_ATTRS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m patterns \u001b[38;5;241m=\u001b[39m [[\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Pattern for prepositional object (PO)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     },\n\u001b[1;32m     20\u001b[0m ]]\n\u001b[1;32m     22\u001b[0m matcher \u001b[38;5;241m=\u001b[39m DependencyMatcher(nlp\u001b[38;5;241m.\u001b[39mvocab)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPO_DO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_indirect_object\u001b[39m(sentence):\n\u001b[1;32m     26\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp(sentence)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spacy/matcher/dependencymatcher.pyx:174\u001b[0m, in \u001b[0;36mspacy.matcher.dependencymatcher.DependencyMatcher.add\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spacy/matcher/dependencymatcher.pyx:125\u001b[0m, in \u001b[0;36mspacy.matcher.dependencymatcher.DependencyMatcher._validate_input\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E099] Invalid pattern: the first node of pattern should be an anchor node. The node should only contain RIGHT_ID and RIGHT_ATTRS."
     ]
    }
   ],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "\n",
    "\n",
    "# Define the patterns for PO and DO\n",
    "patterns = [[\n",
    "    # Pattern for prepositional object (PO)\n",
    "    {\n",
    "        \"RIGHT_ID\": \"prep\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"prep\"},\n",
    "        \"LEFT_ID\": \"obj\",\n",
    "        \"LEFT_ATTRS\": {\"DEP\": {\"IN\": [\"dobj\", \"dative\"]}},\n",
    "    },\n",
    "    # Pattern for double object (DO)\n",
    "    {\n",
    "        \"LEFT_ID\": \"dobj\",\n",
    "        \"LEFT_ATTRS\": {},\n",
    "        \"RIGHT_ID\": \"dative\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"dative\", \"ENT_TYPE\": {\"NOT_IN\": [\"GPE\", \"LOC\"]}},\n",
    "    },\n",
    "]]\n",
    "\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "matcher.add(\"PO_DO\", patterns)\n",
    "\n",
    "def extract_indirect_object(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    matches = matcher(doc)\n",
    "    if matches and matches[0][0] == 1:\n",
    "        dobj = matches[0][1]\n",
    "        iobj = next((token for token in dobj.children if token.dep_ == \"dative\"), None)\n",
    "        if iobj:\n",
    "            return iobj.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711791c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b3375c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f38025b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076743b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e633cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62064d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract direct objects \n",
    "def extract_direct_object(sentence):\n",
    "    # split the sentence into list\n",
    "    tokens = sentence.split()\n",
    "    direct_object = \"\"\n",
    "    \n",
    "    doc = nlp(sentence)\n",
    "    tokens_matchers = [matchers.dep_ for matchers in doc]\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        print(tokens[i], \",\", tokens_matchers[i])\n",
    "    \n",
    "    # get the position of the direct object\n",
    "    dobj_index = tokens_matchers.index(\"dobj\")\n",
    "    # now find the object\n",
    "    direct_object_word = tokens[dobj_index]\n",
    "    \n",
    "    object_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "    # Get the full direct object \n",
    "    for chunk in object_phrases:\n",
    "        if direct_object_word in chunk:\n",
    "            direct_object = chunk\n",
    "        else:\n",
    "            direct_object = direct_object_word\n",
    "    return direct_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a979eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[laughter] , dep\n",
      "my , dep\n",
      "daughter , dep\n",
      "handed , poss\n",
      "me , nsubj\n",
      "the , ROOT\n",
      "phone , dative\n",
      "and , det\n",
      "said , dobj\n",
      "here , cc\n",
      "dad , conj\n",
      "wake , advmod\n",
      "up , nsubj\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'said'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_direct_object(SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35bd383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df370397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0010b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract indirect objects \n",
    "def extract_indirect_object(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    tokens_matchers = [matchers.dep_ for matchers in doc]\n",
    "    \n",
    "    # get the sentence structure\n",
    "    sentence_structure = clf_stc(sentence)\n",
    "    \n",
    "    indirect_object_word = \"\"\n",
    "    \n",
    "    if sentence_structure == 'DO':\n",
    "        indobj_index = tokens_matchers.index('dative')\n",
    "        indirect_object_word = doc[indobj_index]\n",
    "    elif sentence_structure == 'PO':\n",
    "        indobj_index = tokens_matchers.index('pobj')\n",
    "        indirect_object_word = doc[indobj_index]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    object_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "    #Get the indirect objects\n",
    "    for chunk in object_phrases:\n",
    "        if str(indirect_object_word) in chunk:\n",
    "            indirect_object = chunk\n",
    "\n",
    "    return indirect_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b6336b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_indirect_object(SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12acba54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17ba9e91",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4067800170.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [14]\u001b[0;36m\u001b[0m\n\u001b[0;31m    stop here\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1abf056",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2899b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_1(noun_phrase, sentence):\n",
    "    return len(nltk.word_tokenize(noun_phrase))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff391560",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE = \"The bride gave the fireman the lever\"\n",
    "\n",
    "extract_feature_1(\"fireman\", SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ba156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_2(noun_phrase, sentence):\n",
    "    pos_tags = [pos for (word, pos) in nltk.pos_tag(nltk.word_tokenize(noun_phrase))]\n",
    "    return ' '.join(pos_tags)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_feature_2(\"the fireman\", SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_3(noun_phrase, sentence):\n",
    "    words = nltk.word_tokenize(noun_phrase)\n",
    "    word_freqs = Counter(words)\n",
    "    total_words = len(words)\n",
    "    log_mean_freq = math.log(sum(word_freqs.values()) / total_words)\n",
    "    log_median_freq = math.log(sorted(word_freqs.values())[total_words // 2])\n",
    "    return log_mean_freq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f808388",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_feature_3(\"fireman\", SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb885b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_features(features1, features2):\n",
    "    features = [features1, features2]\n",
    "    #for i in range(len(features1)):\n",
    "        #features.append(features1[i] + features2[i])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b552f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = extract_feature_1(\"the fireman\", SENTENCE)\n",
    "features2 = extract_feature_2(\"the fireman\", SENTENCE)\n",
    "\n",
    "concatenate_features(features1, features2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880045da",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52764b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Define a list of sentences\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted to an embedding']\n",
    "\n",
    "# Compute embeddings for all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277083a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "def alter_sentence(sentence):\n",
    "    # Tokenize the sentence\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # Get the part of speech of each word in the sentence\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Choose a random word to replace\n",
    "    word_to_replace = random.choice(pos_tags)[0]\n",
    "    \n",
    "    # Get the synset of the word\n",
    "    synset = wordnet.synsets(word_to_replace)\n",
    "    \n",
    "    # Choose a random synset\n",
    "    random_synset = random.choice(synset)\n",
    "    \n",
    "    # Get a random word from the chosen synset\n",
    "    random_word = random_synset.lemmas()[random.randint(0, len(random_synset.lemmas())-1)].name()\n",
    "    \n",
    "    # Replace the chosen word with the random word\n",
    "    altered_sentence = ' '.join([random_word if word == word_to_replace else word for word in tokens])\n",
    "    \n",
    "    return altered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317391bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the original sentence\n",
    "sentence = \"The quick brown fox jumps over the lazy guy.\"\n",
    "\n",
    "# Produce an altered version of the sentence\n",
    "altered_sentence = alter_sentence(sentence)\n",
    "\n",
    "# Print the original and altered sentences\n",
    "print(\"Original sentence:\", sentence)\n",
    "print(\"Altered sentence:\", altered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcc4f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

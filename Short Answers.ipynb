{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e818e896",
   "metadata": {},
   "source": [
    "1.\n",
    "10 points. Dependency relations are sometimes tricky for parsers to get right. Using the\n",
    "spacy and spacy-stanza parsers, generate plots of the dependency graphs for \"The doctor\n",
    "gave the spotted lemon to the doctor\" and include them in your submission. Compare\n",
    "the areas where the two graphs are the same and cases where they are different. What\n",
    "factors do you think influenced the behavior of the parsers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457b753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9b0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8ff1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1687fa09",
   "metadata": {},
   "source": [
    "2. 15 points. Describe the features you used in Coding question 2. Did you use features\n",
    "from the list of possible features? Why or why not? If you used features from the lists, did\n",
    "you try multiple combinations of features to get the best performance? Provide a\n",
    "justification for using the features that you did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e66f2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9518f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e168178c",
   "metadata": {},
   "source": [
    "3. 10 points. Which model did you choose to use for sentencetransformers? What\n",
    "reasons did you select this model? If you considered other models, how did you evaluate\n",
    "which one to use? Does your embedding model perform better than your feature-based\n",
    "model? Why do you think it does/doesn’t?\n",
    "Bonus (2 points): Report the performance of a classifier (the MultilayerPerceptron from\n",
    "the supplementary code) that is trained on features extracted from the training data.\n",
    "Build a model that contains both symbolic features and embeddings features. Does this\n",
    "“combined” model perform better or worse than the symbolic-only and embeddings-only\n",
    "models? You do not need to upload your model -- just use the model training code to\n",
    "obtain your performance statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35875c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b42e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de0a9656",
   "metadata": {},
   "source": [
    "\n",
    "4. Bonus Question (3 points): Describe the function you wrote to change the input to the\n",
    "sentence embedding generation model. Why did you make the changes you did? Did you\n",
    "think your changes would help or hurt performance? Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faffa69d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
